# 🧠 训练视觉模型（Vision Model）

> 给电脑看很多张猫和狗的照片，并告诉它每张图的正确答案（猫/狗），  
> 让电脑自己慢慢学会“猫长什么样、狗长什么样”。

---

## 一、基础概念

| **图片** | cat1.jpg、dog1.jpg | 电脑要看的“教材” |
|-----------|-------------------|------------------|
| **标签（label）** | cat **或** dog | 每张图片的正确答案 |
| **模型（model）** | 会“看”的大脑 | 模仿人脑神经元做判断的程序 |

- **train** 是**训练集**，模型在这部分学习。  
- **val** 是**验证集**，模型在这部分考试，看学得好不好。  
- 每个子文件夹的名字就是类别名（cat/dog），文件夹里放对应图片。

---

## 二、导入工具

```python
import torch
from torch import nn
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
```

---

## 三、数据处理

```python
train_tf = transforms.Compose([
    transforms.Resize(256),             # 缩放到256像素
    transforms.RandomCrop(224),         # 随机裁剪成224×224的小图
    transforms.RandomHorizontalFlip(),  # 随机左右翻转（增加多样性）
    transforms.ToTensor(),              # 转成张量（电脑能理解的数字形式）
])
```

电脑看不到“猫”“狗”，它只能看数字。

1. 一张彩色图片是由红（R）、绿（G）、蓝（B）三个颜色通道组成的。  
2. 每个像素点都有三个值（R、G、B），范围是 0–255。  
3. 当我们用 `transforms.ToTensor()` 处理图片时，这张图片会被变成一个这样的数字表格：

```
[通道=3, 高=224, 宽=224]
```

📘 例子：  
一张 224×224 的RGB图，有  
`224 × 224 × 3 = 150,528` 个数字。  
这些数字就是模型的“输入”。

---

## 四、加载图片和label

```python
train_data = datasets.ImageFolder("data/train", transform=train_tf)
val_data = datasets.ImageFolder("data/val", transform=train_tf)

train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
val_loader = DataLoader(val_data, batch_size=32)
```

---

## 五、加载别人训练好的模型

```python
model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
```

由于使用resnet18最后一层的输入量是500，并且任务只识别猫和狗，所以：

> 把ResNet最后那一层（原本是识别1000类）换成我自己的任务——识别2类（猫/狗）

```python
model.fc = nn.Linear(512, 2)
```

---

## 六、如果需要改动卷积层

```python
import torch
from torch import nn
from torchvision import models

model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
model.fc = nn.Linear(model.fc.in_features, num_classes)

# 1) 先全部冻结
for p in model.parameters():
    p.requires_grad = False

# 2) 只解冻最后一个卷积块 + 最后一层
for p in model.layer4.parameters():
    p.requires_grad = True
for p in model.fc.parameters():
    p.requires_grad = True

# 3) 分组设定学习率（卷积块小一点，分类头大一点）
optimizer = torch.optim.AdamW([
    {"params": model.layer4.parameters(), "lr": 3e-5, "weight_decay": 1e-4},
    {"params": model.fc.parameters(), "lr": 3e-4, "weight_decay": 1e-4},
])
```

---

## 七、什么是卷积层？

模型的前几层是卷积层（Convolution Layer），它们的工作就像人类视觉的“边缘探测器”。

- **第一层卷积**：学习看出图片里的边缘、颜色块。  
- **第二层卷积**：组合这些边缘，看出形状。  
- **第三、四层卷积**：看出更复杂的纹理、结构、物体的一部分。

> 举个比喻：  
> 第一层看“这有条线”；  
> 第二层看“这像耳朵”；  
> 第三层看“这像猫的头”；  
> 最后一层说“嗯，这是猫！”

---

## 八、训练时模型的循环

模型会不断地：

1. 拿图片做预测（比如猫 → 猫/狗分数）  
2. 看预测对不对  
3. 算出“错了多少”（损失 loss）  
4. 通过“反向传播（backpropagation）”自动调整卷积层里的数值（叫权重 weight）

这些权重就相当于“模型的记忆”：

- 某个权重会增强“看到耳朵”时的信号；  
- 另一个权重会弱化“背景噪声”。

---

## 九、训练例子流程

假设我们要训练模型识别猫和狗：

1️⃣ 模型看到一张猫图，输出结果 `[猫:0.3, 狗:0.7]`。  
→ 错误，因为应该是猫。  
2️⃣ 计算损失（loss ≈ 0.7）。  
→ 错得多，loss 高。  
3️⃣ 反向传播调整参数。  
→ 让模型下次“看到这种耳朵和胡须”时更倾向于猫。  
4️⃣ 下一轮输入另一张图……  
→ 模型继续修正。

经过成千上万次循环，模型就会越来越懂“猫”和“狗”的特征。

---

## 十、定义损失函数（Loss Function）

```python
criterion = nn.CrossEntropyLoss()  # 计算预测对错
```

这一句定义了 **损失函数 (Loss Function)**。  
它衡量模型“预测得有多离谱”，告诉模型“该怎么改进”。

🌰 举例：

- 真实标签：猫 → [1, 0]  
- 模型预测：[0.2, 0.8]（更像狗）  

CrossEntropyLoss 会算出一个数字（如 1.6），表示“错得多严重”。  
错得越离谱，loss 越大。  
模型的目标是让 loss 越来越小。

### 🧮 CrossEntropyLoss 背后的两步：

1️⃣ **Softmax**：把输出变成概率  
   → 例如 [2.3, -0.5] → [0.91, 0.09]  

2️⃣ **取交叉熵 (Cross Entropy)**：比较预测与真实的差距  
   → 对正确类概率取负对数，正确概率越高，loss越小。  

> 模型对正确类越自信（概率越高），loss 越小。

✅ **为什么常用它？**

- 对多分类任务非常合适；  
- 自动包含 Softmax，不用自己写；  
- 鼓励模型“对正确类更自信，对错误类更不自信”。

---

## 十一、定义优化器（Optimizer）

```python
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # 优化参数
```

**作用：**
> 用损失函数提供的“方向”，去调整模型的参数，让模型越来越准。

- `model.parameters()` → 要改哪些参数（卷积层、全连接层等）  
- `lr=0.001` → 学习率（每次改多少）  
  - 太大：乱跳、学不稳  
  - 太小：学太慢、可能卡住  

### 🧩 常见优化器对比

| 优化器 | 特点 | 优缺点 | 常用场景 |
|---------|------|--------|----------|
| SGD | 基础算法 | 收敛慢，但泛化好 | 大数据集、高精度任务 |
| SGD + Momentum | 加速收敛 | 调参略难 | 图像任务常用 |
| Adam | 自动调节学习率 | 快、易用 | 入门、原型开发 |
| RMSProp | 平衡方向步幅 | 泛化略差 | RNN |
| AdamW | 改进版 Adam | 泛化更好 | 现代标准配置 |

---

## 十二、训练过程

```python
for epoch in range(5):  # 训练5轮
    model.train()  # 进入训练模式
    for imgs, labels in train_loader:
        optimizer.zero_grad()           # 清空梯度
        output = model(imgs)            # 前向传播
        loss = criterion(output, labels)
        loss.backward()                 # 反向传播
        optimizer.step()                # 更新参数
    print(f"Epoch {epoch+1}, Loss={loss.item():.4f}")
```

---

## 十三、反向传播（Backpropagation）

反向传播是神经网络能“学会东西”的灵魂。

类比：**练飞镖**

1️⃣ 你扔一镖（预测）  
2️⃣ 看偏离靶心多远（loss）  
3️⃣ 想“手腕太用力了”（找原因）  
4️⃣ 下次调整手劲（更新参数）  

---

### 模型内部过程：

1️⃣ **前向传播（Forward）**  
输入图片 → 一层层卷积 → 输出 `[猫:0.2, 狗:0.8]`

2️⃣ **计算损失（Loss）**  
真值 `[1, 0]`，预测错了，算出 loss。

3️⃣ **反向传播（Backward）**  
计算每层权重对错误的贡献，利用**链式法则**算梯度。

4️⃣ **优化器更新参数**  
`new_weight = old_weight - learning_rate × gradient`

---

### 数学例子

```text
output = input × weight
目标 = 10
输入 = 2
初始 weight = 3
output = 6
loss = (10 - 6)^2 = 16
```

梯度：
```
d(loss)/d(weight) = 2 × (output - target) × input = -16
```

更新：
```
new_weight = 3 - 0.1 × (-16) = 4.6
```

输出变为 `2×4.6=9.2` → 更接近10 ✅

---

## 十四、为什么要有很多层？

单层网络只能学**线性关系（直线）**，  
现实世界是**非线性**的（复杂曲线）。

- 一层网络：只会画直线决策边界。  
- 多层 + 激活函数：每层都把输入空间“折叠”“拉伸”“旋转”。  
- 前几层：提取边缘、颜色、线条。  
- 中间层：组合成眼睛、耳朵。  
- 后几层：识别“这是猫”“这是狗”。

---

## 十五、验证模型准确率

```python
model.eval()
correct, total = 0, 0

with torch.no_grad():
    for imgs, labels in val_loader:
        output = model(imgs)
        preds = output.argmax(1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

print(f"Accuracy: {correct / total:.2%}")
```

---

## 十六、保存模型

```python
torch.save(model.state_dict(), "catdog_model.pth")
```

---

## ✅ 总结

| 模块 | 作用 |
|------|------|
| **DataLoader** | 提供批次数据 |
| **Transforms** | 图像预处理 |
| **Model (ResNet18)** | 学习特征 |
| **Loss (CrossEntropy)** | 衡量误差 |
| **Optimizer (Adam)** | 更新参数 |
| **Backpropagation** | 核心学习机制 |
| **Accuracy** | 衡量效果 |
