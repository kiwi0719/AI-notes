# 🧠 Prompt Engineering 全面指南

**Prompt（提示词）**： 你输入给 AI 的文字指令。 例如：
"请用简洁的方式解释什么是机器学习，并举一个例子。"

**Engineering（工程）**：
意味着这不是随意聊天，而是通过结构化、可复现的方法去**设计提示**，让模型输出更加稳定、可靠。

------------------------------------------------------------------------

## 🔧 常用 Prompt 工程技巧

  ----------------------------------------------------------------------------------------------------------
  **技巧名称**                         **说明**                   **示例**
  ------------------------------------ -------------------------- ------------------------------------------
  **角色扮演法（Role Prompting）**     让模型扮演特定身份         "你是一名数据科学教授，请解释线性回归。"

  **分步推理法（Chain-of-Thought）**   要求 AI 一步步思考         "请一步步推理你的答案并给出最终结论。"

  **Few-shot 学习**                    提供几个示例，让模型模仿   "例1：...... 例2：...... 现在请生成例3。"

  **思维树（Tree-of-Thought）**        让模型尝试多种路径再择优   "请列出三种解法，并比较哪种最好。"

  **输出模板化（Output Structuring）** 限定输出格式               "用Markdown表格展示结果，每列加标题。"

  **上下文注入（Context Injection）**  加入背景信息提高准确性     "以下是项目背景......
                                                                  请基于此撰写执行计划。"
  ----------------------------------------------------------------------------------------------------------

------------------------------------------------------------------------

## 🧩 LLM 的本质

LLM（Large Language
Model）并不真正"理解语言"，而是通过学习**大量文本的统计规律**，来预测"下一个最可能的词"。

换句话说，它是在执行： \> "看到前文后，预测下一个词的概率。"

核心架构是 **Transformer**（Google 2017年提出），解决了传统 RNN/LSTM
不能高效处理长文本的问题。

------------------------------------------------------------------------

## ⚙️ Transformer 工作原理

输入文本 → 分词（Tokenize） → 向量嵌入（Embedding） → Transformer层 →
输出概率分布。

关键组件包括：

-   **Self-Attention（自注意力）**：让模型生成一个词时考虑整个上下文。
-   **Position Encoding（位置编码）**：标识词的顺序信息。
-   **Feed Forward 层**：进行非线性变换，增强语义表达。
-   **多层堆叠**：逐层提取更抽象的语义特征。

------------------------------------------------------------------------

## 🧠 模型训练阶段

  ---------------------------------------------------------------------------------------
  阶段                          模型学习内容                    数据类型
  ----------------------------- ------------------------------- -------------------------
  **预训练 (Pretraining)**      通用语言结构与知识              Wikipedia、书籍、网页

  **指令微调**                    学会理解人类命令                人类问答对                                                     

  **对齐训练 (RLHF)**           学会"听话"                      人类偏好反馈

  **Fine-tuning**   学会特定任务                    专业语料、企业数据
  ---------------------------------------------------------------------------------------

------------------------------------------------------------------------

## 🪞 模型生成过程

当你输入 Prompt 时：

1.  模型将文字转为 Token。
2.  计算每个可能下一个词的概率。
3.  选择概率最高或采样生成一个词。
4.  将该词加入上下文，重复步骤直到完成。

------------------------------------------------------------------------

## ⚠️ LLM 局限性

  **类别**              **说明**           **举例**
  --------------------- ------------------ --------------------
  🧠 缺乏真正理解       模型只是统计相关   容易胡编事实
  ⏱ 上下文窗口限制      只能记有限字数     长对话会遗忘前文
  📉 无长期记忆         每次对话是独立的   无法记住旧内容
  🧮 推理与算术不稳定   非精确计算器       17×23 可能答错
  💬 数据偏见           会复制语料偏差     输出带倾向性
  🔒 知识截止           截止于特定时间     不了解2024年后事件
  💰 高计算成本         GPU消耗大          成本高、延迟明显
  ⚙️ 可解释性差         难以追踪内部逻辑   属于"黑箱模型"

------------------------------------------------------------------------

## 📈 Self-Attention 的复杂度与优化

Self-Attention 的计算复杂度为：

> **O(n²)**，其中 n 为 token 数。

也就是说，文本越长，计算量呈平方增长。

为此，研究者提出多种优化方案：

  方法                原理                   优缺点
  ------------------- ---------------------- ----------------------
  稀疏注意力          只计算部分Token关系    节省计算，可能丢信息
  局部窗口注意力      只关注邻近区域         保局部性，失全局性
  RoPE 旋转位置编码   通过角度旋转表示距离   GPT-4、LLaMA-3已采用
  滑动窗口推理        分段滑动缓存关键层     降低内存压力
  外部记忆（RAG）     外部数据库检索上下文   实用性强
  层级总结            自动压缩早期内容       适用于长对话

RoPE（旋转位置编码）可以理解为： \>
每个词像指针，句子是表盘；词在句子中位置不同，对应不同角度旋转。

------------------------------------------------------------------------

## 🎯 为什么要 Fine-tuning？

虽然 GPT、LLaMA 等模型很强，但它们的知识是**通用的**。
当我们希望模型擅长某个**特定领域任务**（如法律问答、客服、学术写作），就需要微调来：

-   强化特定领域表现
-   让模型遵守统一语气与格式
-   简化 Prompt 设计
-   提高一致性与可靠性

训练数据格式通常为 JSONL：

``` json
{"prompt": "Translate this to French: Hello", "completion": "Bonjour"}
```

------------------------------------------------------------------------

## 🔗 Prompt Chaining（提示链）

Prompt Chaining 是把复杂任务分解为多步 Prompt，每步输出是下一步输入。

**优点：**

-   强化分步思考
-   易于调试、追踪
-   提升逻辑可控性

  步骤     Prompt                                        说明
  -------- --------------------------------------------- --------------
  Step 1   "从以下论文中提取研究问题和方法。"            抽取关键信息
  Step 2   "根据上一步内容，用200字总结论文主要贡献。"   生成摘要
  Step 3   "将摘要翻译为英文，并保持学术语气。"          格式化输出

------------------------------------------------------------------------

## 🧾 RAG（检索增强生成）

RAG 结合"知识检索 + 文本生成"：

1.  **Retrieval（检索）**：从向量数据库（如
    FAISS、Chroma）中查找相关段落；
2.  **Augmented Generation（生成）**：把检索结果注入 Prompt
    中，让模型基于真实资料回答。

------------------------------------------------------------------------

## 🧩 System Prompt 与 User Prompt

  类型                作用             示例
  ------------------- ---------------- ------------------------------
  **System Prompt**   设定角色与语气   "你是一名Monash大学AI助理。"
  **User Prompt**     指定具体任务     "解释什么是敏捷项目管理。"

System Prompt 决定"人格"，User Prompt 决定"任务"。 前者优先级更高。

------------------------------------------------------------------------

## 🧱 Prompt 模板化与自动化

为了批量生成任务，可将 Prompt 模板参数化：

    Act as a {role}. Your task is to analyze {topic} in a {tone} tone.

批量填充示例：

  role           topic             tone
  -------------- ----------------- ------------
  professor      neural networks   academic
  marketer       AI ethics         persuasive
  data analyst   energy trends     neutral

------------------------------------------------------------------------

## 🔁 迭代优化 Prompt

Prompt 工程是一门**实验性科学**。 像调模型一样，不断试错、评估、优化。

优化方向：

1.  缩小任务范围
2.  明确输出格式
3.  提供正反示例（Few-shot）
4.  让模型"反思"推理过程
5.  分析失败案例，逐轮改进

示例：

初版： \> "总结这份报告。"

优化版： \> "请用150字以内总结报告的主要发现，并按以下格式输出：关键趋势
/ 数据支持 / 政策建议。"

------------------------------------------------------------------------

## 🤖 RAG + Multi-Agent 系统（LangChain / LlamaIndex）

现代 AI 应用常采用**多 Agent 架构**：

> 各 Agent 各司其职，如检索、分析、撰写、审校。

例如：

    User Input
     ↓
    Retriever Agent —— 检索知识（RAG）
     ↓
    Analyzer Agent —— 提炼要点
     ↓
    Writer Agent —— 结构化写作
     ↓
    Reviewer Agent —— 质量校验

每个 Agent 都有自己的： - System Prompt（角色定义） - Task
Prompt（执行逻辑） - Memory（上下文记录）

这些模块通过 **LangChain.AgentExecutor** 或 **LlamaIndex.Graph** 串联。

------------------------------------------------------------------------

## 🧮 示例代码概览

### 1️⃣ 构建索引（RAG 基础）

``` python
# build_index.py
from langchain_community.document_loaders import PyPDFDirectoryLoader, TextLoader, DirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings

embed = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
pdfs = PyPDFDirectoryLoader("./docs").load()
txts = DirectoryLoader("./docs", glob="**/*.md", loader_cls=TextLoader).load()
docs = pdfs + txts

splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
chunks = splitter.split_documents(docs)

db = Chroma.from_documents(chunks, embedding=embed, persist_directory="./chroma_db")
db.persist()
print("Index built and persisted.")
```

------------------------------------------------------------------------

### 2️⃣ 定义多 Agent 与流程编排

包含 Researcher、Analyst、Writer、Reviewer 四个阶段，依次串联。

核心思想： \> "RAG 检索 → 逻辑分析 → 引用写作 → 自动审校"， \>
实现一个具备知识感知、可验证输出的多智能体系统。

------------------------------------------------------------------------

### 3️⃣ 最终执行逻辑

``` python
if __name__ == "__main__":
 q = "请总结这些文件中关于‘数字教育战略中的AI应用’的核心目标与指标，并给出引用。"
 final, note = answer(q)
 print("n=== FINAL ===n", final)
 print("n=== REVIEW ===n", note)
```

------------------------------------------------------------------------

✅ **总结**：

Prompt 工程并非只是"写好问题"，而是：

> 一门结合 **语言设计 + 模型认知 + 系统思维** 的新型工程学。

通过掌握结构化思维（Chain、RAG、Agent、模板、迭代）， 你不仅能让 LLM
更"聪明"，还可让它**成为真正可控的智能协作者**。
