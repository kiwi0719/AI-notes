# 🧠 Prompt Engineering 全面指南

**Prompt（提示词）**：你输入给 AI 的文字指令。  
例如：  
> “请用简洁的方式解释什么是机器学习，并举一个例子。”

**Engineering（工程）**：通过结构化、可复现的方法去**设计提示**，让模型输出更加稳定、可靠。

---

## 🔧 常用 Prompt 工程技巧

| 技巧名称 | 说明 | 示例 |
| --- | --- | --- |
| 角色扮演法（Role Prompting） | 让模型扮演特定身份 | “你是一名数据科学教授，请解释线性回归。” |
| 分步推理法（Chain-of-Thought） | 要求 AI 一步步思考 | “请一步步推理你的答案并给出最终结论。” |
| Few-shot 学习 | 提供几个示例，让模型模仿 | “例1：…… 例2：…… 现在请生成例3。” |
| 思维树（Tree-of-Thought） | 让模型尝试多种路径再择优 | “请列出三种解法，并比较哪种最好。” |
| 输出模板化（Output Structuring） | 限定输出格式 | “用 Markdown 表格展示结果，每列加标题。” |
| 上下文注入（Context Injection） | 加入背景信息提高准确性 | “以下是项目背景…… 请基于此撰写执行计划。” |

---

## 🧩 LLM 的本质

LLM（Large Language Model）并不真正“理解语言”，而是通过学习**大量文本的统计规律**来预测“下一个最可能的词”。

换句话说，它是在执行：  
> 看到前文后，预测下一个词的概率。

核心架构是 **Transformer**（Google 2017 年提出），解决了传统 RNN/LSTM 不能高效处理长文本的问题。

---

## ⚙️ Transformer 工作原理

输入文本 → 分词（Tokenize） → 向量嵌入（Embedding） → Transformer 层 → 输出概率分布。

**关键组件**：

- **Self-Attention（自注意力）**：生成一个词时考虑整个上下文。  
- **Position Encoding（位置编码）**：标识词的顺序信息。  
- **Feed Forward 层**：非线性变换，增强语义表达。  
- **多层堆叠**：逐层提取更抽象的语义特征。  

---

## 🧠 模型训练阶段

| 阶段 | 模型学习内容 | 数据类型 |
| --- | --- | --- |
| 预训练（Pretraining） | 通用语言结构与知识 | Wikipedia、书籍、网页 |
| 指令微调（Instruction Tuning） | 学会理解人类命令 | 人类问答对 |
| 对齐训练（RLHF） | 学会“听话” | 人类偏好反馈 |
| Fine-tuning | 学会特定任务 | 专业语料、企业数据 |

---

## 🪞 模型生成过程

当你输入 Prompt 时：

1. 模型将文字转为 Token；  
2. 计算每个可能下一个词的概率；  
3. 选择概率最高或采样生成一个词；  
4. 将该词加入上下文，重复直到完成输出。  

---

## ⚠️ LLM 局限性

| 类别 | 说明 | 举例 |
| --- | --- | --- |
| 🧠 缺乏真正理解 | 模型只是统计相关 | 容易“胡编事实” |
| ⏱ 上下文窗口限制 | 只能记有限字数 | 长对话会遗忘前文 |
| 📉 无长期记忆 | 每次对话是独立的 | 无法记住旧内容 |
| 🧮 推理与算术不稳定 | 非精确计算器 | 17×23 可能答错 |
| 💬 数据偏见 | 会复制语料偏差 | 输出带倾向性 |
| 🔒 知识截止 | 截止于特定时间 | 不了解截止后事件 |
| 💰 高计算成本 | GPU 消耗大 | 成本高、延迟明显 |
| ⚙️ 可解释性差 | 难以追踪内部逻辑 | “黑箱模型” |

---

## 📈 Self-Attention 的复杂度与优化

Self-Attention 的计算复杂度：**O(n²)**，其中 _n_ 为 token 数。  
上下文长度翻倍，计算量约增至 4 倍。为此有多种优化：

| 方法 | 原理 | 优缺点 |
| --- | --- | --- |
| 稀疏注意力（Sparse Attention） | 只计算部分 token 间注意力 | 省算力，可能丢信息 |
| 局部窗口注意力（Local Attention） | 仅在相邻区间计算 | 保局部性，弱全局依赖 |
| RoPE 旋转位置编码 | 通过角度旋转表示相对距离 | 已用于 GPT-4、LLaMA-3 |
| 滑动窗口推理（Sliding Window） | 滑窗并缓存关键层 | 降低内存压力 |
| 外部记忆（Memory/RAG） | 外部数据库按需检索上下文 | 实用性强 |
| 层级总结（Summarization） | 自动压缩早期内容 | 适合长对话 |

> 比喻：每个词像表盘上的指针；RoPE 为不同位置赋予不同旋转角度，模型比较“夹角”来感知距离。

---

## 🎯 为什么要 Fine-tuning？

虽然 GPT、LLaMA 等模型很强，但它们的知识是**通用的**。当我们希望模型擅长某个**特定领域任务**（如法律问答、客服、学术写作），就需要微调：

- 强化该领域表现  
- 让模型遵守统一语气与格式  
- 简化 Prompt 设计  
- 提高一致性与可靠性  

**训练数据格式（JSONL）示例：**
```json
{"prompt": "Translate this to French: Hello", "completion": "Bonjour"}
```

---

## 🔗 Prompt Chaining（提示链）

将复杂任务拆成多步 Prompt，每步输出是下一步的输入。

**优点**：分步思考、易调试、逻辑可控。

| 步骤 | Prompt | 说明 |
| --- | --- | --- |
| Step 1 | “从以下论文中提取研究问题和方法。” | 抽取关键信息 |
| Step 2 | “根据上一步内容，用 200 字总结论文主要贡献。” | 生成摘要 |
| Step 3 | “将摘要翻译为英文，并保持学术语气。” | 格式化输出 |

---

## 🧾 RAG（检索增强生成）

1. **Retrieval（检索）**：从向量数据库（如 FAISS、Chroma）查找相关段落；  
2. **Augmented Generation（生成）**：把检索结果注入 Prompt，让模型基于真实资料回答。

---

## 🧩 System Prompt 与 User Prompt

| 类型 | 作用 | 示例 |
| --- | --- | --- |
| System Prompt | 设定角色与语气 | “你是一名 Monash 大学 AI 助理。” |
| User Prompt | 指定具体任务 | “解释什么是敏捷项目管理。” |

> System Prompt 决定“人格”，User Prompt 决定“任务”；前者优先级更高。

---

## 🧱 Prompt 模板化与自动化

模板参数化可批量生成任务：

```
Act as a {role}. Your task is to analyze {topic} in a {tone} tone.
```

| role | topic | tone |
| --- | --- | --- |
| professor | neural networks | academic |
| marketer | AI ethics | persuasive |
| data analyst | energy trends | neutral |

---

## 🔁 迭代优化 Prompt（调参与试错）

优化方向：

1. 缩小任务范围  
2. 明确输出格式  
3. 提供正反示例（Few-shot）  
4. 要求“反思式”推理过程  
5. 复盘失败案例并逐轮改进  

**示例**：  
初版：  
“总结这份报告。”  
优化版：  
“请用 150 字以内总结报告主要发现，并按以下格式输出：**关键趋势 / 数据支持 / 政策建议**。”

---

## 🤖 RAG + Multi‑Agent 系统（LangChain / LlamaIndex）

多 Agent 架构让各模块各司其职（检索、分析、撰写、审校）：

```
User Input
  ↓
Retriever Agent —— 检索知识（RAG）
  ↓
Analyzer Agent —— 提炼要点
  ↓
Writer Agent —— 结构化写作
  ↓
Reviewer Agent —— 质量校验
```

每个 Agent 拥有：System Prompt、Task Prompt、Memory，并通过 **LangChain.AgentExecutor** 或 **LlamaIndex.Graph** 串联。

---

## 🧮 示例代码概览

### 1) 构建索引（RAG 基础）

```python
# build_index.py
from langchain_community.document_loaders import PyPDFDirectoryLoader, TextLoader, DirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings

embed = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
pdfs = PyPDFDirectoryLoader("./docs").load()
txts = DirectoryLoader("./docs", glob="**/*.md", loader_cls=TextLoader).load()
docs = pdfs + txts

splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
chunks = splitter.split_documents(docs)

db = Chroma.from_documents(chunks, embedding=embed, persist_directory="./chroma_db")
db.persist()
print("Index built and persisted.")
```

### 2) 多 Agent 与流程编排（概念）

> “RAG 检索 → 逻辑分析 → 引用写作 → 自动审校”，形成具备知识感知与可验证输出的多智能体流程。

### 3) 最终执行逻辑（示意）

```python
if __name__ == "__main__":
    q = "请总结这些文件中关于‘数字教育战略中的AI应用’的核心目标与指标，并给出引用。"
    final, note = answer(q)
    print("\n=== FINAL ===\n", final)
    print("\n=== REVIEW ===\n", note)
```

---

## ✅ 总结

Prompt 工程并非只是“写好问题”，而是：**语言设计 + 模型认知 + 系统思维** 的结合。  
掌握 Chain、RAG、Agent、模板与迭代等方法，能让 LLM 更“聪明”，并成为**可控的智能协作者**。
